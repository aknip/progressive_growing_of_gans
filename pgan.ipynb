{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created on c7 east coast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nsadawi/Download-Large-File-From-Google-Drive-Using-Python/blob/master/Download-Large-File-from-Google-Drive.ipynb\n",
    "\n",
    "#taken from this StackOverflow answer: https://stackoverflow.com/a/39225039\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/open?id=19IW_CWna76GQhdm98wonYSlSpLBJczzu\n",
    "file_id = '19IW_CWna76GQhdm98wonYSlSpLBJczzu'\n",
    "destination = '/storage/pgan.zip'\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /storage/pgan.zip -d /storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm pgan.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 283M\r\n",
      "drwxr-xr-x 2 root root 4.0K Oct 10 08:28 .\r\n",
      "drwxr-xr-x 4 root root 4.0K Oct 11 07:26 ..\r\n",
      "-rw-r--r-- 1 root root  916 Oct  9 20:47 config.txt\r\n",
      "-rw-r--r-- 1 root root 5.4K Oct 10 08:29 events.out.tfevents.1539118734.dcc1935ea5c7\r\n",
      "-rw-r--r-- 1 root root 6.7M Oct  9 20:47 fakes000000.png\r\n",
      "-rw-r--r-- 1 root root  26K Oct  9 20:58 fakes000140.png\r\n",
      "-rw-r--r-- 1 root root  31K Oct  9 21:16 fakes000260.png\r\n",
      "-rw-r--r-- 1 root root  42K Oct  9 21:50 fakes000360.png\r\n",
      "-rw-r--r-- 1 root root  88K Oct  9 22:36 fakes000440.png\r\n",
      "-rw-r--r-- 1 root root 115K Oct  9 23:51 fakes000520.png\r\n",
      "-rw-r--r-- 1 root root 273K Oct 10 01:19 fakes000580.png\r\n",
      "-rw-r--r-- 1 root root 322K Oct 10 02:58 fakes000640.png\r\n",
      "-rw-r--r-- 1 root root 633K Oct 10 04:33 fakes000680.png\r\n",
      "-rw-r--r-- 1 root root 835K Oct 10 06:33 fakes000720.png\r\n",
      "-rw-r--r-- 1 root root 897K Oct 10 08:28 fakes000760.png\r\n",
      "-rw-r--r-- 1 root root  11K Oct 10 08:29 log.txt\r\n",
      "-rw-r--r-- 1 root root 265M Oct 10 08:28 network-snapshot-000760.pkl\r\n",
      "-rw-r--r-- 1 root root 9.0M Oct  9 20:47 reals.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah ./results/000-pgan-celebahq100-preset-v2-1gpu-fp32/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements-pip.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from \"celebahq-100-jpg\"\n",
      "Creating dataset \"datasets/teschtxxx\"\n",
      "Added 100 images.                       \n"
     ]
    }
   ],
   "source": [
    "dataset_tool.create_from_images('datasets/celebahq100','celebahq-100-jpg', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r results/001-pgan-celebahq100-preset-v2-1gpu-fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Resume after training intrerruption from snapshot (.pkl files - automatically generated every 10 ticks/epochs):\n",
    "Change parameters in train.py (line 145):\n",
    "resume_run_id           = './results/full-path-to-snapshot-002705.pkl',  \n",
    "resume_snapshot         = None,\n",
    "resume_kimg             = 2705.9,    # taken from logfile (eg using snapshot after tick20: \"tick 20  kimg 2705.9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue training\n",
    "Change parameters in train.py (line 145): \n",
    "\n",
    "network_snapshot_ticks  = 2, \n",
    "\n",
    "resume_run_id = 0, # './results/000-pgan-celebahq100-preset-v2-1gpu-fp32/network-snapshot-000760.pkl',\n",
    "\n",
    "resume_snapshot = None, \n",
    "\n",
    "resume_kimg = 760.8, # taken from logfile\n",
    "\n",
    "=> reduce network_snapshot_ticks to 2 !\n",
    "\n",
    "=> only changing resume_run_id = 000 does not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 13, in <module>\r\n",
      "    import config\r\n",
      "  File \"/home/paperspace/Documents/progressive_growing_of_gans/config.py\", line 27, in <module>\r\n",
      "    tf_config = EasyDict()  # TensorFlow session config, set by tfutil.init_tf().\r\n",
      "  File \"/home/paperspace/Documents/progressive_growing_of_gans/config.py\", line 13, in __init__\r\n",
      "    def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs)\r\n",
      "TypeError: super() takes at least 1 argument (0 given)\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
